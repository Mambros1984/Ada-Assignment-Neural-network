{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pima-Prediction.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "8Kjc2MnP0IJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pima Indian Diabetes Prediction"
      ]
    },
    {
      "metadata": {
        "id": "kX4JYtl8UsxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
        "\n",
        "The task is to build a model that could predict with a reasonable accuracy if a person is more likely to develop diabetes or not using the Pima Indian Diabetes data.\n",
        "\n",
        "This is a kind of Binary problem as the answer could be ***diabetes = true*** or ***diabetes =false***. Such problem can be faced with classification algorithms and considered that the task is a prediction it can be identified as a supervised machine learning task.\n",
        "\n",
        "Given the amount of variables that could affect the life of a human being, setting the target accuracy to 70% might be a reasonable goal. This will be the bottom of the acceptable range."
      ]
    },
    {
      "metadata": {
        "id": "c2hvaca2XraG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PREPARING THE DATA\n",
        "The process will involve the following stpes:\n",
        "\n",
        "\n",
        "1.   Get the data needed\n",
        "2.   Inspect and clean the data\n",
        "3.   Explore the data\n",
        "4.   Mold the data to tidy data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VZVSObYw0IJN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import some basic libraries.\n",
        "* Pandas - provided data frames\n",
        "* matplotlib.pyplot - plotting support\n",
        "\n",
        "Use Magic %matplotlib to display graphics inline instead of in a popup window.\n"
      ]
    },
    {
      "metadata": {
        "id": "oWuHhOgO0IJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd                 # pandas is a dataframe library\n",
        "import matplotlib.pyplot as plt      # matplotlib.pyplot plots data\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NnmMC7U80IJR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading and Reviewing the Data"
      ]
    },
    {
      "metadata": {
        "id": "M-GzITcAYWyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Importing the dataset from the github link\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dUB23LWn0IJS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Mambros1984/Ada-Assignment-Neural-network/master/pima-data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAXJ8iw9Yeo_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Checking the size of the dataset. \n",
        "The first value is the number of rows; the second is the number of columns.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0Urickuy0IJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "409e0f79-4085-41eb-dd5f-cdee09c211a9"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "JRATrJhPYyJ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Inspecting the data checking the beginning rows of the dataframe through the **head()** method and specifying the number of lines to return.\n",
        "\n",
        "N.B = notice that the first row has a 0 index and the Pandas dataframe has column names which are used to access specific rows and columns. They can be used together to access value belonging to specific rows and columns.\n"
      ]
    },
    {
      "metadata": {
        "id": "3MQ6ReV_0IJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "76ec9742-67e6-4ab7-d8c5-035cfbb949df"
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>skin</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1.3790</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>1.1426</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0.9062</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3790</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age    skin  diabetes  \n",
              "0   50  1.3790      True  \n",
              "1   31  1.1426     False  \n",
              "2   32  0.0000      True  \n",
              "3   21  0.9062     False  \n",
              "4   33  1.3790      True  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "id": "Y8LA2Sv7ZHkj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Inspecting the data checking the ending lines of the dataframe through the **tail()** method.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PtRMxYXC0IJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8fc73d89-d13c-42ee-ded2-bb76ba4c2789"
      },
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>skin</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>1.8912</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0638</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0.9062</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>1.2214</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  \\\n",
              "763        10           101            76         48      180  32.9   \n",
              "764         2           122            70         27        0  36.8   \n",
              "765         5           121            72         23      112  26.2   \n",
              "766         1           126            60          0        0  30.1   \n",
              "767         1            93            70         31        0  30.4   \n",
              "\n",
              "     diab_pred  age    skin  diabetes  \n",
              "763      0.171   63  1.8912     False  \n",
              "764      0.340   27  1.0638     False  \n",
              "765      0.245   30  0.9062     False  \n",
              "766      0.349   47  0.0000      True  \n",
              "767      0.315   23  1.2214     False  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "DLA8nsvT0IJg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Definition of features\n",
        "From the metadata on the data source we have the following definition of the features.\n",
        "\n",
        "| Feature  | Description | Comments |\n",
        "|--------------|-------------|--------|\n",
        "| num_preg     | number of pregnancies         |\n",
        "| glucose_conc | Plasma glucose concentration a 2 hours in an oral glucose tolerance test         |\n",
        "| diastolic_bp | Diastolic blood pressure (mm Hg) |\n",
        "| thickness | Triceps skin fold thickness (mm) |\n",
        "|insulin | 2-Hour serum insulin (mu U/ml) |\n",
        "| bmi |  Body mass index (weight in kg/(height in m)^2) |\n",
        "| diab_pred |  Diabetes pedigree function |\n",
        "| Age (years) | Age (years)|\n",
        "| skin | ???? | What is this? |\n",
        "| diabetes | Class variable (1=True, 0=False) |  Why is our data boolean (True/False)? |\n"
      ]
    },
    {
      "metadata": {
        "id": "cTEIg_3HaK4F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CLEANING THE DATASET\n",
        "\n",
        "Will now check if there is the need to eliminate columns based on the following criteria:\n",
        "\n",
        "\n",
        "1.   Column not used;\n",
        "2.   Column with null values;\n",
        "3.   Duplicate columns.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GvKw9X_e0IJg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check for null values"
      ]
    },
    {
      "metadata": {
        "id": "-8ounON_a3bg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The panda method ***isnull()*** will make it easy to check if there is any null value in the dataframe."
      ]
    },
    {
      "metadata": {
        "id": "h4dwq3Gn0IJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "512d8a53-4770-4cdd-e2f7-297c82d6aa1c"
      },
      "cell_type": "code",
      "source": [
        "df.isnull().values.any()\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {
        "id": "yfGrTvaM0IJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Correlated Feature Check"
      ]
    },
    {
      "metadata": {
        "id": "HS8IAyfm0IJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Helper function that displays correlation by color.  Black is most correlated, White least."
      ]
    },
    {
      "metadata": {
        "id": "KM6KJTvM0IJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_corr(df, size=11):\n",
        "    \"\"\"\n",
        "    Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
        "\n",
        "    Input:\n",
        "        df: pandas DataFrame\n",
        "        size: vertical and horizontal size of the plot\n",
        "\n",
        "    Displays:\n",
        "        matrix of correlation between columns.  white-light_grey-dark_grey-black => less to more correlated\n",
        "                                                0 ------------------>  1\n",
        "                                                Expect a black line running from top left to bottom right\n",
        "    \"\"\"\n",
        "\n",
        "    corr = df.corr()    # data frame correlation function\n",
        "    fig, ax = plt.subplots(figsize=(size, size))\n",
        "    ax.matshow(corr)   # color code the rectangles by correlation value\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns)  # draw x tick marks\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)  # draw y tick marks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCSHsvtZ0IJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "990ddbba-6ac2-444d-c366-43032ec05348"
      },
      "cell_type": "code",
      "source": [
        "plot_corr(df)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAJ1CAYAAAAVGAKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb13199a4e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QBg0LeiIb2uZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice the column names running across the horizontal and vertical axes.\n",
        "\n",
        "This is a matrix showing which columns have data values that are correlated with values in other columns.\n",
        "\n",
        "Black means the columns are highly positively correlated. \n",
        "\n",
        "Since we have the same columns along the horizontal and vertical axes, black squares are expected on a diagonal from upper left to the lower right.\n",
        "\n",
        "There are actually 2 squares in positions they're not expected to be in, the **skin** and the **thickness**. This means there are strong correlations between these 2 columns.\n",
        "\n",
        "Checking now the correlation numbers to verify the result shown on the graph to see how correlated the **skin** and the **thickness** are."
      ]
    },
    {
      "metadata": {
        "id": "qFfkS0B_0IJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "54466898-d76d-41f0-a660-d853372ce7c8"
      },
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>skin</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>num_preg</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129459</td>\n",
              "      <td>0.141282</td>\n",
              "      <td>-0.081672</td>\n",
              "      <td>-0.073535</td>\n",
              "      <td>0.017683</td>\n",
              "      <td>-0.033523</td>\n",
              "      <td>0.544341</td>\n",
              "      <td>-0.081672</td>\n",
              "      <td>0.221898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glucose_conc</th>\n",
              "      <td>0.129459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.152590</td>\n",
              "      <td>0.057328</td>\n",
              "      <td>0.331357</td>\n",
              "      <td>0.221071</td>\n",
              "      <td>0.137337</td>\n",
              "      <td>0.263514</td>\n",
              "      <td>0.057328</td>\n",
              "      <td>0.466581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diastolic_bp</th>\n",
              "      <td>0.141282</td>\n",
              "      <td>0.152590</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.207371</td>\n",
              "      <td>0.088933</td>\n",
              "      <td>0.281805</td>\n",
              "      <td>0.041265</td>\n",
              "      <td>0.239528</td>\n",
              "      <td>0.207371</td>\n",
              "      <td>0.065068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thickness</th>\n",
              "      <td>-0.081672</td>\n",
              "      <td>0.057328</td>\n",
              "      <td>0.207371</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.436783</td>\n",
              "      <td>0.392573</td>\n",
              "      <td>0.183928</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.074752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insulin</th>\n",
              "      <td>-0.073535</td>\n",
              "      <td>0.331357</td>\n",
              "      <td>0.088933</td>\n",
              "      <td>0.436783</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.197859</td>\n",
              "      <td>0.185071</td>\n",
              "      <td>-0.042163</td>\n",
              "      <td>0.436783</td>\n",
              "      <td>0.130548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>0.017683</td>\n",
              "      <td>0.221071</td>\n",
              "      <td>0.281805</td>\n",
              "      <td>0.392573</td>\n",
              "      <td>0.197859</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140647</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.392573</td>\n",
              "      <td>0.292695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diab_pred</th>\n",
              "      <td>-0.033523</td>\n",
              "      <td>0.137337</td>\n",
              "      <td>0.041265</td>\n",
              "      <td>0.183928</td>\n",
              "      <td>0.185071</td>\n",
              "      <td>0.140647</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.033561</td>\n",
              "      <td>0.183928</td>\n",
              "      <td>0.173844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0.544341</td>\n",
              "      <td>0.263514</td>\n",
              "      <td>0.239528</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>-0.042163</td>\n",
              "      <td>0.036242</td>\n",
              "      <td>0.033561</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>0.238356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skin</th>\n",
              "      <td>-0.081672</td>\n",
              "      <td>0.057328</td>\n",
              "      <td>0.207371</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.436783</td>\n",
              "      <td>0.392573</td>\n",
              "      <td>0.183928</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.074752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diabetes</th>\n",
              "      <td>0.221898</td>\n",
              "      <td>0.466581</td>\n",
              "      <td>0.065068</td>\n",
              "      <td>0.074752</td>\n",
              "      <td>0.130548</td>\n",
              "      <td>0.292695</td>\n",
              "      <td>0.173844</td>\n",
              "      <td>0.238356</td>\n",
              "      <td>0.074752</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              num_preg  glucose_conc  diastolic_bp  thickness   insulin  \\\n",
              "num_preg      1.000000      0.129459      0.141282  -0.081672 -0.073535   \n",
              "glucose_conc  0.129459      1.000000      0.152590   0.057328  0.331357   \n",
              "diastolic_bp  0.141282      0.152590      1.000000   0.207371  0.088933   \n",
              "thickness    -0.081672      0.057328      0.207371   1.000000  0.436783   \n",
              "insulin      -0.073535      0.331357      0.088933   0.436783  1.000000   \n",
              "bmi           0.017683      0.221071      0.281805   0.392573  0.197859   \n",
              "diab_pred    -0.033523      0.137337      0.041265   0.183928  0.185071   \n",
              "age           0.544341      0.263514      0.239528  -0.113970 -0.042163   \n",
              "skin         -0.081672      0.057328      0.207371   1.000000  0.436783   \n",
              "diabetes      0.221898      0.466581      0.065068   0.074752  0.130548   \n",
              "\n",
              "                   bmi  diab_pred       age      skin  diabetes  \n",
              "num_preg      0.017683  -0.033523  0.544341 -0.081672  0.221898  \n",
              "glucose_conc  0.221071   0.137337  0.263514  0.057328  0.466581  \n",
              "diastolic_bp  0.281805   0.041265  0.239528  0.207371  0.065068  \n",
              "thickness     0.392573   0.183928 -0.113970  1.000000  0.074752  \n",
              "insulin       0.197859   0.185071 -0.042163  0.436783  0.130548  \n",
              "bmi           1.000000   0.140647  0.036242  0.392573  0.292695  \n",
              "diab_pred     0.140647   1.000000  0.033561  0.183928  0.173844  \n",
              "age           0.036242   0.033561  1.000000 -0.113970  0.238356  \n",
              "skin          0.392573   0.183928 -0.113970  1.000000  0.074752  \n",
              "diabetes      0.292695   0.173844  0.238356  0.074752  1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {
        "id": "NTnhwHGHdZFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice the 1.00 value running down the diagonal of the table. This is because of each column with itself which is of course a perfect correlation. \n",
        "\n",
        "The same happens for the **thickness** and **skin** columns which is not expected. Having two features that move together adds no additional information.\n",
        "\n",
        "The solution to this problem is to drop at least one column, in this case the **skin** column."
      ]
    },
    {
      "metadata": {
        "id": "K4FJ_hBt0IJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fd18d144-bd04-46d3-fa2c-dd51f92ce94a"
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>skin</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1.3790</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>1.1426</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0.9062</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3790</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age    skin  diabetes  \n",
              "0   50  1.3790      True  \n",
              "1   31  1.1426     False  \n",
              "2   32  0.0000      True  \n",
              "3   21  0.9062     False  \n",
              "4   33  1.3790      True  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "WP7TiDkA0IJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The skin and thickness columns are correlated 1 to 1.  Dropping the skin column using the ***del*** command."
      ]
    },
    {
      "metadata": {
        "id": "GAuunP1Q0IJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del df['skin']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcHWYvlleVHu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking the **skin** column has been dropped."
      ]
    },
    {
      "metadata": {
        "id": "MbSKEDig0IJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e8432e1f-f729-4662-e3de-2f81e80d0c2c"
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age  diabetes  \n",
              "0   50      True  \n",
              "1   31     False  \n",
              "2   32      True  \n",
              "3   21     False  \n",
              "4   33      True  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "hEPy9uwT0IJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check for additional correlations to make sure the dataset is clean, therefore no black squares should be seen other than on the diagonal."
      ]
    },
    {
      "metadata": {
        "id": "GTUp9yIX0IJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "6bb19e15-7978-4f91-fc10-38c575a836c3"
      },
      "cell_type": "code",
      "source": [
        "plot_corr(df)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAJ1CAYAAAAVGAKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb1318a0438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TTQEhwK20IJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The correlations look good.  There appear to be no coorelated columns."
      ]
    },
    {
      "metadata": {
        "id": "Yaq-qt4q0IJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mold Data"
      ]
    },
    {
      "metadata": {
        "id": "grvKmclQ0IJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Types\n",
        "\n",
        "Inspect data types to see if there are any issues.  Data should be numeric."
      ]
    },
    {
      "metadata": {
        "id": "y4eGJwnM0IKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "96e40add-55b3-466a-dc9b-9269c209952d"
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age  diabetes  \n",
              "0   50      True  \n",
              "1   31     False  \n",
              "2   32      True  \n",
              "3   21     False  \n",
              "4   33      True  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "B_wK84QT0IKC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change diabetes from boolean to integer, True=1, False=0\n",
        "\n",
        "A mapping dictionary will be used to define those values as the Panda dataframe will do the work iterating through the data."
      ]
    },
    {
      "metadata": {
        "id": "_tXH1d1n0IKD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "diabetes_map = {True : 1, False : 0}\n",
        "df['diabetes'] = df['diabetes'].map(diabetes_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cML_1JUo0IKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verifying that the diabetes data type has been changed."
      ]
    },
    {
      "metadata": {
        "id": "38HwVf3-0IKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7a059f96-1abc-46aa-db8d-d6266b257cda"
      },
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age  diabetes  \n",
              "0   50         1  \n",
              "1   31         0  \n",
              "2   32         1  \n",
              "3   21         0  \n",
              "4   33         1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {
        "id": "i5JNtKFc0IKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check for null values"
      ]
    },
    {
      "metadata": {
        "id": "BBHXFAhg0IKI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50a2bb5e-177a-4c59-84d2-56c1d8bd8098"
      },
      "cell_type": "code",
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "metadata": {
        "id": "G_1PJ1S40IKK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No obvious null values."
      ]
    },
    {
      "metadata": {
        "id": "8L7-k4AE0IKL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check class distribution \n",
        "\n",
        "At this point the class distribution will be checked analysing how many **diabetes = true** and **diabetes = false** are in the dataset to understand if the information are suitable to train the model and get reasonable results.\n",
        "\n",
        "If the dataset was containing either a vast majority of true cases and a few false or viceversa, there would have been the need to gather more information to be able to proceed to build an acceptable model.\n",
        "\n",
        "In this case the data seem split in a way that will allow the model to be trained without implementing more information."
      ]
    },
    {
      "metadata": {
        "id": "je734ZnV0IKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e110437-d64d-43e9-d01b-103c3994a77f"
      },
      "cell_type": "code",
      "source": [
        "num_obs = len(df)\n",
        "num_true = len(df.loc[df['diabetes'] == 1])\n",
        "num_false = len(df.loc[df['diabetes'] == 0])\n",
        "print(\"Number of True cases:  {0} ({1:2.2f}%)\".format(num_true, (num_true/num_obs) * 100))\n",
        "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false/num_obs) * 100))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of True cases:  268 (34.90%)\n",
            "Number of False cases: 500 (65.10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LXlpcKT4iKEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TRAINING THE ALGORITHM"
      ]
    },
    {
      "metadata": {
        "id": "svFMJXiq0IKO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Spliting the data \n",
        "\n",
        "Data will be splitted in 70% for training and 30% for testing.\n",
        "\n",
        "The algorithm will be trained with the training set while the testing set will be used to verify the quality of the training. The test set will never be used for training.\n",
        "\n",
        "The ***scikit-learn***  train test split method will be used for this task.\n",
        "\n",
        "The feature columns and the predicted column will be defined and the prepared data will be split in two dataframes, one containing the feature columns and the other with the predicted diabetes result for each observation row.\n",
        "\n",
        "A value of 0.30 (30%) is assigned to the **test_size** value.\n",
        "\n",
        "These dataframes and the test size are passed to the **train test split** function which splits the original dataframes and returns four NumPy arrays of data.\n",
        "\n",
        "The **random_state = 42** is an important feature that sets the seed for the random number generator used as part of the splitting process. Setting the seed to a constant insures that if the function is run again, the split will be identical."
      ]
    },
    {
      "metadata": {
        "id": "6v-yOWwP0IKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "feature_col_names = ['num_preg', 'glucose_conc', 'diastolic_bp', 'thickness', 'insulin', 'bmi', 'diab_pred', 'age']\n",
        "predicted_class_names = ['diabetes']\n",
        "\n",
        "X = df[feature_col_names].values     # predictor feature columns (8 X m)\n",
        "y = df[predicted_class_names].values # predicted class (1=true, 0=false) column (1 X m)\n",
        "split_test_size = 0.30\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test_size, random_state=42) \n",
        "                            # test_size = 0.3 is 30%, 42 is the answer to everything"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KSl_lORQ0IKQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ensure that the split of the data  desired is 70% train, 30% test .\n",
        "\n",
        "In this case the values are very close to the original data, therefore this is an acceptable split for the model."
      ]
    },
    {
      "metadata": {
        "id": "5EWSXLZ40IKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fda0f10e-7786-4249-d90e-4c516271c63d"
      },
      "cell_type": "code",
      "source": [
        "print(\"{0:0.2f}% in training set\".format((len(X_train)/len(df.index)) * 100))\n",
        "print(\"{0:0.2f}% in test set\".format((len(X_test)/len(df.index)) * 100))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69.92% in training set\n",
            "30.08% in test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PC-4van50IKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Verifying predicted value was split correctly\n",
        "\n",
        "Comparing the **diabetes = true** or **false** values among the ***Original dataset*** , ***Training dataset*** and ***Test dataset*** ."
      ]
    },
    {
      "metadata": {
        "id": "yWf_Bar10IKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ee9d2e14-35cd-4fce-9f0c-f9f1da89e2eb"
      },
      "cell_type": "code",
      "source": [
        "print(\"Original True  : {0} ({1:0.2f}%)\".format(len(df.loc[df['diabetes'] == 1]), (len(df.loc[df['diabetes'] == 1])/len(df.index)) * 100.0))\n",
        "print(\"Original False : {0} ({1:0.2f}%)\".format(len(df.loc[df['diabetes'] == 0]), (len(df.loc[df['diabetes'] == 0])/len(df.index)) * 100.0))\n",
        "print(\"\")\n",
        "print(\"Training True  : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train) * 100.0)))\n",
        "print(\"Training False : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train) * 100.0)))\n",
        "print(\"\")\n",
        "print(\"Test True      : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test) * 100.0)))\n",
        "print(\"Test False     : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test) * 100.0)))\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original True  : 268 (34.90%)\n",
            "Original False : 500 (65.10%)\n",
            "\n",
            "Training True  : 188 (35.01%)\n",
            "Training False : 349 (64.99%)\n",
            "\n",
            "Test True      : 80 (34.63%)\n",
            "Test False     : 151 (65.37%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ynswPG3Q0IKY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Post-split Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "usSfu7rI0IKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hidden Missing Values"
      ]
    },
    {
      "metadata": {
        "id": "R-Gh5mcR0IKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d26604f0-94a4-4f02-dae7-815e81db96c7"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age  diabetes  \n",
              "0   50         1  \n",
              "1   31         0  \n",
              "2   32         1  \n",
              "3   21         0  \n",
              "4   33         1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "9vP55frB0IKd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice the value 0 for the **thickness** on the row **2**, that is physically impossible, therefore that is a hidden missing value.\n",
        "\n",
        "Of those fields only the **insulin** column might have valid zero values. And even in this, zero is likely not correct.\n",
        "\n",
        "This seem like a missing data problem and can e overridden in 3 ways:\n",
        "\n",
        "\n",
        "*   Ignoring those values;\n",
        "*   Dropping the rows;\n",
        "*   Replacing the values.\n",
        "\n",
        "Of 768 rows, 374 are missing insulin values. This can't be ignored as it's almost 50% of data but at the same time those values will cause a bias.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cpkxhfL90IKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5e793322-0787-4811-b6f7-e12a2cc707af"
      },
      "cell_type": "code",
      "source": [
        "print(\"# rows in dataframe {0}\".format(len(df)))\n",
        "print(\"# rows missing glucose_conc: {0}\".format(len(df.loc[df['glucose_conc'] == 0])))\n",
        "print(\"# rows missing diastolic_bp: {0}\".format(len(df.loc[df['diastolic_bp'] == 0])))\n",
        "print(\"# rows missing thickness: {0}\".format(len(df.loc[df['thickness'] == 0])))\n",
        "print(\"# rows missing insulin: {0}\".format(len(df.loc[df['insulin'] == 0])))\n",
        "print(\"# rows missing bmi: {0}\".format(len(df.loc[df['bmi'] == 0])))\n",
        "print(\"# rows missing diab_pred: {0}\".format(len(df.loc[df['diab_pred'] == 0])))\n",
        "print(\"# rows missing age: {0}\".format(len(df.loc[df['age'] == 0])))"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# rows in dataframe 768\n",
            "# rows missing glucose_conc: 5\n",
            "# rows missing diastolic_bp: 35\n",
            "# rows missing thickness: 227\n",
            "# rows missing insulin: 374\n",
            "# rows missing bmi: 11\n",
            "# rows missing diab_pred: 0\n",
            "# rows missing age: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EsTHbVTL0IKi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Impute with the mean\n",
        "\n",
        "Imputing is the method to replace those **0** values in the **insulin** column.\n",
        "\n",
        "It will involve the creation of a new ***imputer*** object which will replace the missing values with the mean for all the values on the axis zero which is column.\n",
        "\n",
        "The **imputer fit_transform** function has been used to create a new NumPy array with any feature value of zero replaced by the mean for the column. This is applied to both training and test feature value separately as the values in the dataset are different."
      ]
    },
    {
      "metadata": {
        "id": "KJbYtHxW0IKj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "#Impute with mean all 0 readings\n",
        "fill_0 = Imputer(missing_values=0, strategy=\"mean\", axis=0)\n",
        "\n",
        "X_train = fill_0.fit_transform(X_train)\n",
        "X_test = fill_0.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "choi5fs-0IKw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Forest\n",
        "\n",
        "Random forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
        "\n",
        "The process will involve to :\n",
        "\n",
        "\n",
        "1.   Import the model;\n",
        "2.   Train the model;\n",
        "3.   Check the accuracy on the training data;\n",
        "4.   Check the accuracy on the test data.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8rM19X8W0IKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0cb0b41f-2c90-4135-bfc7-3afe611e3010"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)      # Create random forest object\n",
        "rf_model.fit(X_train, y_train.ravel()) "
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "metadata": {
        "id": "Of_Goozm0IK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict Training Data"
      ]
    },
    {
      "metadata": {
        "id": "tuVKaNd80IK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37571a25-0b37-463f-926a-3cbc7326b311"
      },
      "cell_type": "code",
      "source": [
        "rf_predict_train = rf_model.predict(X_train)\n",
        "# training metrics\n",
        "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, rf_predict_train)))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E9FbYcan0IK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict Test Data"
      ]
    },
    {
      "metadata": {
        "id": "3VHcxEH60IK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cce31ad-e496-40f9-a5ce-45aa65dedce1"
      },
      "cell_type": "code",
      "source": [
        "rf_predict_test = rf_model.predict(X_test)\n",
        "\n",
        "# training metrics\n",
        "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, rf_predict_test)))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8fWxuYJWqS4r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The accuracy of the training data is great, on the other side the accuracy of the test data looks very poor compared to the first one.\n",
        "This happens because the **Random forest** model is overfitting the training data, the model has learned the training data too well. The overfitting could be handled with special tuning parameters called ***Regularisation hyperparameters*** or through the **cross validation**.\n",
        "\n",
        "The **cross validation** uses multiple subsets of the training data during the training process.\n",
        "\n",
        "\n",
        "In the matrix below the values are stored in the following way:\n",
        "\n",
        "*   Top left = True Negative\n",
        "*   Top right  = False Positive (in a perfect classifier it would be 0)\n",
        "*   Bottom left = False Negative (in a perfect classifier it would be 0)\n",
        "*   Bottom right = True Positive\n",
        "\n",
        "The **recall** column (true positive rate and sensitivity) looks pretty poor as it returns only 54% . It should show how well the model is predicting the diabetes when the result is actually diabetes.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rVU5HfSe0IK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a82bd8aa-fc46-4252-97c4-9b4f4771becf"
      },
      "cell_type": "code",
      "source": [
        "print(metrics.confusion_matrix(y_test, rf_predict_test) )\n",
        "print(\"\")\n",
        "print(\"Classification Report\")\n",
        "print(metrics.classification_report(y_test, rf_predict_test))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[121  30]\n",
            " [ 37  43]]\n",
            "\n",
            "Classification Report\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.77      0.80      0.78       151\n",
            "          1       0.59      0.54      0.56        80\n",
            "\n",
            "avg / total       0.70      0.71      0.71       231\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_qnR38_I0IK9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "The other model taken in consideration is the **logistic regression** that despite the name is a classification algorithm.\n",
        "\n",
        "As done in the previous model the algorithm will be trained and the results will be evaluated."
      ]
    },
    {
      "metadata": {
        "id": "fwihV-Du0IK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a4558e46-9819-472e-bf9e-0abff5e28e0a"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model =LogisticRegression(C=0.7, random_state=42)\n",
        "lr_model.fit(X_train, y_train.ravel())\n",
        "lr_predict_test = lr_model.predict(X_test)\n",
        "\n",
        "# training metrics\n",
        "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, lr_predict_test)))\n",
        "print(metrics.confusion_matrix(y_test, lr_predict_test) )\n",
        "print(\"\")\n",
        "print(\"Classification Report\")\n",
        "print(metrics.classification_report(y_test, lr_predict_test))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7446\n",
            "[[128  23]\n",
            " [ 36  44]]\n",
            "\n",
            "Classification Report\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.78      0.85      0.81       151\n",
            "          1       0.66      0.55      0.60        80\n",
            "\n",
            "avg / total       0.74      0.74      0.74       231\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XmUHhEKMtvvH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The accuracy in this case looks promising, 74%, but the recall is still low, 55%."
      ]
    },
    {
      "metadata": {
        "id": "0gZPD49i0ILA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting regularization parameter to try to retun a higher recall.\n",
        "\n",
        "The while loop will try C values from zero to 4.9 in increments of 0.1. \n",
        "\n",
        "For each C value, its LogisticRegression object is created and trained with the training data, and then used to predict the test results. Each test recall score is computed and the highest recall score is recorded.\n",
        "That score is used to get the C value that produced the highest recall score.\n",
        "The recall scores have been plotted versus regularisation value so that an idea of how recall changes with different regularization values can be achieved."
      ]
    },
    {
      "metadata": {
        "id": "FyojyWK-0ILB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "ac2e3580-cbb2-4a71-a2d4-735697db75ea"
      },
      "cell_type": "code",
      "source": [
        "C_start = 0.1\n",
        "C_end = 5\n",
        "C_inc = 0.1\n",
        "\n",
        "C_values, recall_scores = [], []\n",
        "\n",
        "C_val = C_start\n",
        "best_recall_score = 0\n",
        "while (C_val < C_end):\n",
        "    C_values.append(C_val)\n",
        "    lr_model_loop = LogisticRegression(C=C_val, random_state=42)\n",
        "    lr_model_loop.fit(X_train, y_train.ravel())\n",
        "    lr_predict_loop_test = lr_model_loop.predict(X_test)\n",
        "    recall_score = metrics.recall_score(y_test, lr_predict_loop_test)\n",
        "    recall_scores.append(recall_score)\n",
        "    if (recall_score > best_recall_score):\n",
        "        best_recall_score = recall_score\n",
        "        best_lr_predict_test = lr_predict_loop_test\n",
        "        \n",
        "    C_val = C_val + C_inc\n",
        "\n",
        "best_score_C_val = C_values[recall_scores.index(best_recall_score)]\n",
        "print(\"1st max value of {0:.3f} occured at C={1:.3f}\".format(best_recall_score, best_score_C_val))\n",
        "\n",
        "%matplotlib inline \n",
        "plt.plot(C_values, recall_scores, \"-\")\n",
        "plt.xlabel(\"C value\")\n",
        "plt.ylabel(\"recall score\")\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1st max value of 0.613 occured at C=1.400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'recall score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgoiIjJESUFERIb8fym65v2+Uvf6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb12ff10cc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VHRoTDa2vEJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The recall value is still far from 70%, it's 61% .\n",
        "\n",
        "The issue could be cause by the nature of the dataset that had more non-diabetes results than diabetes results. This is an unbalance between those 2 classes.\n",
        "\n",
        "To avoid this the ***class_weight=\"balanced\"*** will be passed as hyperparameter in the loop to find the best value of C."
      ]
    },
    {
      "metadata": {
        "id": "DQP_GoYM0ILD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logisitic regression with class_weight='balanced'"
      ]
    },
    {
      "metadata": {
        "id": "ksPtHd_00ILE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "49339a63-147f-4e5f-b4ba-7383038de120"
      },
      "cell_type": "code",
      "source": [
        "C_start = 0.1\n",
        "C_end = 5\n",
        "C_inc = 0.1\n",
        "\n",
        "C_values, recall_scores = [], []\n",
        "\n",
        "C_val = C_start\n",
        "best_recall_score = 0\n",
        "while (C_val < C_end):\n",
        "    C_values.append(C_val)\n",
        "    lr_model_loop = LogisticRegression(C=C_val, class_weight=\"balanced\", random_state=42)\n",
        "    lr_model_loop.fit(X_train, y_train.ravel())\n",
        "    lr_predict_loop_test = lr_model_loop.predict(X_test)\n",
        "    recall_score = metrics.recall_score(y_test, lr_predict_loop_test)\n",
        "    recall_scores.append(recall_score)\n",
        "    if (recall_score > best_recall_score):\n",
        "        best_recall_score = recall_score\n",
        "        best_lr_predict_test = lr_predict_loop_test\n",
        "        \n",
        "    C_val = C_val + C_inc\n",
        "\n",
        "best_score_C_val = C_values[recall_scores.index(best_recall_score)]\n",
        "print(\"1st max value of {0:.3f} occured at C={1:.3f}\".format(best_recall_score, best_score_C_val))\n",
        "\n",
        "%matplotlib inline \n",
        "plt.plot(C_values, recall_scores, \"-\")\n",
        "plt.xlabel(\"C value\")\n",
        "plt.ylabel(\"recall score\")"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1st max value of 0.738 occured at C=0.300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'recall score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fb12fe3f898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CoDA_Domv6PW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The **LogisticRegression** will be performed now adding the C value to the best one from the loop above and the class balance hyperparameter will be included as well."
      ]
    },
    {
      "metadata": {
        "id": "c33hCjfr0ILH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "75d97d67-2290-4982-9d8c-83f1984e2007"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model =LogisticRegression( class_weight=\"balanced\", C=best_score_C_val, random_state=42)\n",
        "lr_model.fit(X_train, y_train.ravel())\n",
        "lr_predict_test = lr_model.predict(X_test)\n",
        "\n",
        "# training metrics\n",
        "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, lr_predict_test)))\n",
        "print(metrics.confusion_matrix(y_test, lr_predict_test) )\n",
        "print(\"\")\n",
        "print(\"Classification Report\")\n",
        "print(metrics.classification_report(y_test, lr_predict_test))\n",
        "print(metrics.recall_score(y_test, lr_predict_test))"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7143\n",
            "[[106  45]\n",
            " [ 21  59]]\n",
            "\n",
            "Classification Report\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.83      0.70      0.76       151\n",
            "          1       0.57      0.74      0.64        80\n",
            "\n",
            "avg / total       0.74      0.71      0.72       231\n",
            "\n",
            "0.7375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "73ZqwTWAwN0w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The accuracy is now 71% and the recall is 74% !\n"
      ]
    },
    {
      "metadata": {
        "id": "YDo68xtO0ILK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LogisticRegressionCV\n",
        "\n",
        "The **LogisticRegression** function will be now used together with the **cross validation** method to check if it will improve the results.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IJzHyp_10ILK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8009a227-f815-48d4-ed12-cc9d75f538ae"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "lr_cv_model = LogisticRegressionCV(n_jobs=-1, random_state=42, Cs=3, cv=10, refit=False, class_weight=\"balanced\")  # set number of jobs to -1 which uses all cores to parallelize\n",
        "lr_cv_model.fit(X_train, y_train.ravel())"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=3, class_weight='balanced', cv=10, dual=False,\n",
              "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
              "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=42,\n",
              "           refit=False, scoring=None, solver='lbfgs', tol=0.0001,\n",
              "           verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "metadata": {
        "id": "0FcVig67xCN0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The recall score is not quite what has been achieved in the previous run by tuning the score against the test data, but by using cross validation  it's more likely to score better on real-world data.\n",
        "\n",
        "Also with this ensemble algorithms there are a lot of parameters that can be adjusted and implementing them might boost the score results."
      ]
    },
    {
      "metadata": {
        "id": "Vm86X5-K0ILN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict on Test data"
      ]
    },
    {
      "metadata": {
        "id": "LZqx0NEO0ILO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d2f9994d-ce1d-40bf-c9c5-7ee3cafe3e3a"
      },
      "cell_type": "code",
      "source": [
        "lr_cv_predict_test = lr_cv_model.predict(X_test)\n",
        "\n",
        "# training metrics\n",
        "print(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, lr_cv_predict_test)))\n",
        "print(metrics.confusion_matrix(y_test, lr_cv_predict_test) )\n",
        "print(\"\")\n",
        "print(\"Classification Report\")\n",
        "print(metrics.classification_report(y_test, lr_cv_predict_test))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7013\n",
            "[[108  43]\n",
            " [ 26  54]]\n",
            "\n",
            "Classification Report\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          0       0.81      0.72      0.76       151\n",
            "          1       0.56      0.68      0.61        80\n",
            "\n",
            "avg / total       0.72      0.70      0.71       231\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L12IDSHHSmY8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CLUSTERING ALGORITHM**\n",
        "\n",
        "The **diabetes** column values will be converted from categorical variables into numeric form using the Label Encoder"
      ]
    },
    {
      "metadata": {
        "id": "oKeH7P0F0ILP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b9576667-8da2-40ec-98bd-b5d709f0cc3c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['diabetes'] = le.fit_transform(df['diabetes'].astype(str))\n",
        "df.head()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age  diabetes  \n",
              "0   50         1  \n",
              "1   31         0  \n",
              "2   32         1  \n",
              "3   21         0  \n",
              "4   33         1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "l-fsjnKcz00k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The estimator for the clustering algorithm is being setup here and the only hyperparameter that needs to be passed in is the **bandwidth**.\n",
        "Smaller values of bandwidth will result in tall, skinny kernels, while larger values of bandwidth will result in short and fat kernels."
      ]
    },
    {
      "metadata": {
        "id": "9gmOiRAoOWpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3092b593-3ab7-48e3-9583-35fa15177a6e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MeanShift\n",
        "\n",
        "analyzer = MeanShift(bandwidth = 90)\n",
        "analyzer.fit(df)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MeanShift(bandwidth=90, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
              "     n_jobs=1, seeds=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "metadata": {
        "id": "vg7P1wCX0hY8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The **estimate_bandwidth** is a helper function to help estimate a good value for the bandwidth based on the data."
      ]
    },
    {
      "metadata": {
        "id": "-UCHOCCYOoyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7df03215-d7bf-436a-b150-cb23afed4601"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import estimate_bandwidth\n",
        "estimate_bandwidth(df)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.16372168931862"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "metadata": {
        "id": "-CTpOX3lO19I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = analyzer.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vynP-bfAO9lA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3b3a451-adf7-4286-fca3-7e9823899f73"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(labels)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "metadata": {
        "id": "i6x7R3U_1JV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Above can be seen that a bandwidth of 90 produces 4 clusters. Each of this groups will contain persons with similar characteristics.\n",
        "\n",
        "A new column called **cluster_group** will be added to store information about what cluster each person belongs to."
      ]
    },
    {
      "metadata": {
        "id": "MopufTRcPJr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "df['cluster_group'] = np.nan\n",
        "data_length = len(df)\n",
        "for i in range(data_length):\n",
        "  df.iloc[i, df.columns.get_loc('cluster_group')] = labels[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFWMF7Xh1vRd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking if the new column has been added at the end of the dataframe."
      ]
    },
    {
      "metadata": {
        "id": "KIZ-eiunPdjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "09c3e5c2-c22a-46cb-a017-5bc7db487ddb"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>cluster_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  diab_pred  \\\n",
              "0         6           148            72         35        0  33.6      0.627   \n",
              "1         1            85            66         29        0  26.6      0.351   \n",
              "2         8           183            64          0        0  23.3      0.672   \n",
              "3         1            89            66         23       94  28.1      0.167   \n",
              "4         0           137            40         35      168  43.1      2.288   \n",
              "\n",
              "   age  diabetes  cluster_group  \n",
              "0   50         1            0.0  \n",
              "1   31         0            0.0  \n",
              "2   32         1            0.0  \n",
              "3   21         0            0.0  \n",
              "4   33         1            0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "metadata": {
        "id": "u1sTvyEM12Dp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The describe function will display the information about the entire dataset. "
      ]
    },
    {
      "metadata": {
        "id": "8xXpC33ZPizq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "cc526bb0-6531-432f-a400-d63230f12280"
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>cluster_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>768.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.845052</td>\n",
              "      <td>120.894531</td>\n",
              "      <td>69.105469</td>\n",
              "      <td>20.536458</td>\n",
              "      <td>79.799479</td>\n",
              "      <td>31.992578</td>\n",
              "      <td>0.471876</td>\n",
              "      <td>33.240885</td>\n",
              "      <td>0.348958</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.369578</td>\n",
              "      <td>31.972618</td>\n",
              "      <td>19.355807</td>\n",
              "      <td>15.952218</td>\n",
              "      <td>115.244002</td>\n",
              "      <td>7.884160</td>\n",
              "      <td>0.331329</td>\n",
              "      <td>11.760232</td>\n",
              "      <td>0.476951</td>\n",
              "      <td>0.303536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>0.243750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>30.500000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.372500</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>140.250000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>127.250000</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>0.626250</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         num_preg  glucose_conc  diastolic_bp   thickness     insulin  \\\n",
              "count  768.000000    768.000000    768.000000  768.000000  768.000000   \n",
              "mean     3.845052    120.894531     69.105469   20.536458   79.799479   \n",
              "std      3.369578     31.972618     19.355807   15.952218  115.244002   \n",
              "min      0.000000      0.000000      0.000000    0.000000    0.000000   \n",
              "25%      1.000000     99.000000     62.000000    0.000000    0.000000   \n",
              "50%      3.000000    117.000000     72.000000   23.000000   30.500000   \n",
              "75%      6.000000    140.250000     80.000000   32.000000  127.250000   \n",
              "max     17.000000    199.000000    122.000000   99.000000  846.000000   \n",
              "\n",
              "              bmi   diab_pred         age    diabetes  cluster_group  \n",
              "count  768.000000  768.000000  768.000000  768.000000     768.000000  \n",
              "mean    31.992578    0.471876   33.240885    0.348958       0.083333  \n",
              "std      7.884160    0.331329   11.760232    0.476951       0.303536  \n",
              "min      0.000000    0.078000   21.000000    0.000000       0.000000  \n",
              "25%     27.300000    0.243750   24.000000    0.000000       0.000000  \n",
              "50%     32.000000    0.372500   29.000000    0.000000       0.000000  \n",
              "75%     36.600000    0.626250   41.000000    1.000000       0.000000  \n",
              "max     67.100000    2.420000   81.000000    1.000000       3.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "metadata": {
        "id": "Gzn04gKk2hEz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following mean function will perform a group by using the cluster_group column and find the mean for each cluster.\n",
        "\n",
        "This will be the average for all characteristics within each group."
      ]
    },
    {
      "metadata": {
        "id": "jyJwmWTxPy8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9e805f1c-0090-45e2-cc51-37e525aa0f67"
      },
      "cell_type": "code",
      "source": [
        "diabete_cluster_data = df.groupby(['cluster_group']).mean()\n",
        "diabete_cluster_data"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster_group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>3.858956</td>\n",
              "      <td>118.035261</td>\n",
              "      <td>68.873061</td>\n",
              "      <td>19.636107</td>\n",
              "      <td>54.727786</td>\n",
              "      <td>31.709591</td>\n",
              "      <td>0.462307</td>\n",
              "      <td>33.207334</td>\n",
              "      <td>0.332863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>3.709091</td>\n",
              "      <td>154.272727</td>\n",
              "      <td>71.745455</td>\n",
              "      <td>31.472727</td>\n",
              "      <td>356.618182</td>\n",
              "      <td>35.280000</td>\n",
              "      <td>0.559709</td>\n",
              "      <td>33.090909</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>78.666667</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>674.666667</td>\n",
              "      <td>39.233333</td>\n",
              "      <td>1.147667</td>\n",
              "      <td>35.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>30.100000</td>\n",
              "      <td>0.398000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               num_preg  glucose_conc  diastolic_bp  thickness     insulin  \\\n",
              "cluster_group                                                                \n",
              "0.0            3.858956    118.035261     68.873061  19.636107   54.727786   \n",
              "1.0            3.709091    154.272727     71.745455  31.472727  356.618182   \n",
              "2.0            4.000000    162.000000     78.666667  32.000000  674.666667   \n",
              "3.0            1.000000    189.000000     60.000000  23.000000  846.000000   \n",
              "\n",
              "                     bmi  diab_pred        age  diabetes  \n",
              "cluster_group                                             \n",
              "0.0            31.709591   0.462307  33.207334  0.332863  \n",
              "1.0            35.280000   0.559709  33.090909  0.545455  \n",
              "2.0            39.233333   1.147667  35.333333  0.333333  \n",
              "3.0            30.100000   0.398000  59.000000  1.000000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "metadata": {
        "id": "J3LLOnnk25Q1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following method will return the number of samples that exist in each cluster and make the table above more understandable.\n",
        "\n",
        "It seems there are 2 clusters that are sufficient data points for it to be actually significant. The last 2 clusters have just 3 and 1 persons in them and there isn't much that can be learned from those two.\n",
        "\n",
        "The first cluster with 709 persons is by far the most common one with an average age of 33 and the diabetes rate is almost the same as the whole dataset. \n",
        "The amount of insulin they get compared to the other clusters is very low. and can be noticed that in the second cluster (55 persons) this goes together with an higher diabetes rate, 54%.\n",
        "\n",
        "Last two clusters don't tell much as they are way different in many values from the first two and that could mean those are edge cases scenarios."
      ]
    },
    {
      "metadata": {
        "id": "VTa11iS2QLn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0f88f622-cda8-487e-dad3-af9c97bdea7c"
      },
      "cell_type": "code",
      "source": [
        "diabete_cluster_data['Counts'] = pd.Series(df.groupby(['cluster_group']).size())\n",
        "diabete_cluster_data"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>Counts</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster_group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>3.858956</td>\n",
              "      <td>118.035261</td>\n",
              "      <td>68.873061</td>\n",
              "      <td>19.636107</td>\n",
              "      <td>54.727786</td>\n",
              "      <td>31.709591</td>\n",
              "      <td>0.462307</td>\n",
              "      <td>33.207334</td>\n",
              "      <td>0.332863</td>\n",
              "      <td>709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>3.709091</td>\n",
              "      <td>154.272727</td>\n",
              "      <td>71.745455</td>\n",
              "      <td>31.472727</td>\n",
              "      <td>356.618182</td>\n",
              "      <td>35.280000</td>\n",
              "      <td>0.559709</td>\n",
              "      <td>33.090909</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>78.666667</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>674.666667</td>\n",
              "      <td>39.233333</td>\n",
              "      <td>1.147667</td>\n",
              "      <td>35.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>846.000000</td>\n",
              "      <td>30.100000</td>\n",
              "      <td>0.398000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               num_preg  glucose_conc  diastolic_bp  thickness     insulin  \\\n",
              "cluster_group                                                                \n",
              "0.0            3.858956    118.035261     68.873061  19.636107   54.727786   \n",
              "1.0            3.709091    154.272727     71.745455  31.472727  356.618182   \n",
              "2.0            4.000000    162.000000     78.666667  32.000000  674.666667   \n",
              "3.0            1.000000    189.000000     60.000000  23.000000  846.000000   \n",
              "\n",
              "                     bmi  diab_pred        age  diabetes  Counts  \n",
              "cluster_group                                                     \n",
              "0.0            31.709591   0.462307  33.207334  0.332863     709  \n",
              "1.0            35.280000   0.559709  33.090909  0.545455      55  \n",
              "2.0            39.233333   1.147667  35.333333  0.333333       3  \n",
              "3.0            30.100000   0.398000  59.000000  1.000000       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "metadata": {
        "id": "8-Hox4pN5RI6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Funciont to describe the persons belonging to the first cluster."
      ]
    },
    {
      "metadata": {
        "id": "SNsO41X_Qzv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "827ab331-0db0-42f7-d8f2-9348bc656fba"
      },
      "cell_type": "code",
      "source": [
        "df[df['cluster_group'] == 0 ].describe()"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>cluster_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.000000</td>\n",
              "      <td>709.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.858956</td>\n",
              "      <td>118.035261</td>\n",
              "      <td>68.873061</td>\n",
              "      <td>19.636107</td>\n",
              "      <td>54.727786</td>\n",
              "      <td>31.709591</td>\n",
              "      <td>0.462307</td>\n",
              "      <td>33.207334</td>\n",
              "      <td>0.332863</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.376534</td>\n",
              "      <td>30.701224</td>\n",
              "      <td>19.868372</td>\n",
              "      <td>16.017210</td>\n",
              "      <td>69.081959</td>\n",
              "      <td>7.924295</td>\n",
              "      <td>0.318774</td>\n",
              "      <td>11.690483</td>\n",
              "      <td>0.471571</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.365000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>36.100000</td>\n",
              "      <td>0.607000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>199.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>67.100000</td>\n",
              "      <td>2.420000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         num_preg  glucose_conc  diastolic_bp   thickness     insulin  \\\n",
              "count  709.000000    709.000000    709.000000  709.000000  709.000000   \n",
              "mean     3.858956    118.035261     68.873061   19.636107   54.727786   \n",
              "std      3.376534     30.701224     19.868372   16.017210   69.081959   \n",
              "min      0.000000      0.000000      0.000000    0.000000    0.000000   \n",
              "25%      1.000000     98.000000     62.000000    0.000000    0.000000   \n",
              "50%      3.000000    114.000000     72.000000   22.000000    0.000000   \n",
              "75%      6.000000    136.000000     80.000000   32.000000  105.000000   \n",
              "max     17.000000    199.000000    122.000000   99.000000  240.000000   \n",
              "\n",
              "              bmi   diab_pred         age    diabetes  cluster_group  \n",
              "count  709.000000  709.000000  709.000000  709.000000          709.0  \n",
              "mean    31.709591    0.462307   33.207334    0.332863            0.0  \n",
              "std      7.924295    0.318774   11.690483    0.471571            0.0  \n",
              "min      0.000000    0.078000   21.000000    0.000000            0.0  \n",
              "25%     27.000000    0.240000   24.000000    0.000000            0.0  \n",
              "50%     32.000000    0.365000   29.000000    0.000000            0.0  \n",
              "75%     36.100000    0.607000   41.000000    1.000000            0.0  \n",
              "max     67.100000    2.420000   81.000000    1.000000            0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "metadata": {
        "id": "vx5fxSYL5V0i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function displaying each person belonging to the first cluster."
      ]
    },
    {
      "metadata": {
        "id": "PwiU8ZlJRTL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "f669bb51-6eea-4d07-b607-73e15699ab0e"
      },
      "cell_type": "code",
      "source": [
        "df[df['cluster_group'] == 0 ]"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_preg</th>\n",
              "      <th>glucose_conc</th>\n",
              "      <th>diastolic_bp</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>diab_pred</th>\n",
              "      <th>age</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>cluster_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>110</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.6</td>\n",
              "      <td>0.191</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>168</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.537</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>10</td>\n",
              "      <td>139</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.1</td>\n",
              "      <td>1.441</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>166</td>\n",
              "      <td>72</td>\n",
              "      <td>19</td>\n",
              "      <td>175</td>\n",
              "      <td>25.8</td>\n",
              "      <td>0.587</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.484</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>84</td>\n",
              "      <td>47</td>\n",
              "      <td>230</td>\n",
              "      <td>45.8</td>\n",
              "      <td>0.551</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7</td>\n",
              "      <td>107</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29.6</td>\n",
              "      <td>0.254</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>103</td>\n",
              "      <td>30</td>\n",
              "      <td>38</td>\n",
              "      <td>83</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.183</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>96</td>\n",
              "      <td>34.6</td>\n",
              "      <td>0.529</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3</td>\n",
              "      <td>126</td>\n",
              "      <td>88</td>\n",
              "      <td>41</td>\n",
              "      <td>235</td>\n",
              "      <td>39.3</td>\n",
              "      <td>0.704</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.4</td>\n",
              "      <td>0.388</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7</td>\n",
              "      <td>196</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.8</td>\n",
              "      <td>0.451</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>9</td>\n",
              "      <td>119</td>\n",
              "      <td>80</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.263</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>11</td>\n",
              "      <td>143</td>\n",
              "      <td>94</td>\n",
              "      <td>33</td>\n",
              "      <td>146</td>\n",
              "      <td>36.6</td>\n",
              "      <td>0.254</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>10</td>\n",
              "      <td>125</td>\n",
              "      <td>70</td>\n",
              "      <td>26</td>\n",
              "      <td>115</td>\n",
              "      <td>31.1</td>\n",
              "      <td>0.205</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7</td>\n",
              "      <td>147</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.4</td>\n",
              "      <td>0.257</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>97</td>\n",
              "      <td>66</td>\n",
              "      <td>15</td>\n",
              "      <td>140</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0.487</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>13</td>\n",
              "      <td>145</td>\n",
              "      <td>82</td>\n",
              "      <td>19</td>\n",
              "      <td>110</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34.1</td>\n",
              "      <td>0.337</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5</td>\n",
              "      <td>109</td>\n",
              "      <td>75</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.546</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>3</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>11</td>\n",
              "      <td>54</td>\n",
              "      <td>24.8</td>\n",
              "      <td>0.267</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>8</td>\n",
              "      <td>65</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.600</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>160</td>\n",
              "      <td>36.6</td>\n",
              "      <td>0.453</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>739</th>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>0.293</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>11</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>37</td>\n",
              "      <td>150</td>\n",
              "      <td>42.3</td>\n",
              "      <td>0.785</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>3</td>\n",
              "      <td>102</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>94</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.400</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>1</td>\n",
              "      <td>109</td>\n",
              "      <td>58</td>\n",
              "      <td>18</td>\n",
              "      <td>116</td>\n",
              "      <td>28.5</td>\n",
              "      <td>0.219</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>9</td>\n",
              "      <td>140</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32.7</td>\n",
              "      <td>0.734</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>744</th>\n",
              "      <td>13</td>\n",
              "      <td>153</td>\n",
              "      <td>88</td>\n",
              "      <td>37</td>\n",
              "      <td>140</td>\n",
              "      <td>40.6</td>\n",
              "      <td>1.174</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>84</td>\n",
              "      <td>33</td>\n",
              "      <td>105</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.488</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>1</td>\n",
              "      <td>147</td>\n",
              "      <td>94</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>49.3</td>\n",
              "      <td>0.358</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>74</td>\n",
              "      <td>41</td>\n",
              "      <td>57</td>\n",
              "      <td>46.3</td>\n",
              "      <td>1.096</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>3</td>\n",
              "      <td>187</td>\n",
              "      <td>70</td>\n",
              "      <td>22</td>\n",
              "      <td>200</td>\n",
              "      <td>36.4</td>\n",
              "      <td>0.408</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>6</td>\n",
              "      <td>162</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.3</td>\n",
              "      <td>0.178</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>4</td>\n",
              "      <td>136</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.2</td>\n",
              "      <td>1.182</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>78</td>\n",
              "      <td>39</td>\n",
              "      <td>74</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.261</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>752</th>\n",
              "      <td>3</td>\n",
              "      <td>108</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.223</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>8</td>\n",
              "      <td>154</td>\n",
              "      <td>78</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>32.4</td>\n",
              "      <td>0.443</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>1</td>\n",
              "      <td>128</td>\n",
              "      <td>88</td>\n",
              "      <td>39</td>\n",
              "      <td>110</td>\n",
              "      <td>36.5</td>\n",
              "      <td>1.057</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>7</td>\n",
              "      <td>137</td>\n",
              "      <td>90</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.391</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.3</td>\n",
              "      <td>0.258</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>0.197</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.5</td>\n",
              "      <td>0.278</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>2</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.766</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>761</th>\n",
              "      <td>9</td>\n",
              "      <td>170</td>\n",
              "      <td>74</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.403</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>762</th>\n",
              "      <td>9</td>\n",
              "      <td>89</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.142</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>709 rows  10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     num_preg  glucose_conc  diastolic_bp  thickness  insulin   bmi  \\\n",
              "0           6           148            72         35        0  33.6   \n",
              "1           1            85            66         29        0  26.6   \n",
              "2           8           183            64          0        0  23.3   \n",
              "3           1            89            66         23       94  28.1   \n",
              "4           0           137            40         35      168  43.1   \n",
              "5           5           116            74          0        0  25.6   \n",
              "6           3            78            50         32       88  31.0   \n",
              "7          10           115             0          0        0  35.3   \n",
              "9           8           125            96          0        0   0.0   \n",
              "10          4           110            92          0        0  37.6   \n",
              "11         10           168            74          0        0  38.0   \n",
              "12         10           139            80          0        0  27.1   \n",
              "14          5           166            72         19      175  25.8   \n",
              "15          7           100             0          0        0  30.0   \n",
              "16          0           118            84         47      230  45.8   \n",
              "17          7           107            74          0        0  29.6   \n",
              "18          1           103            30         38       83  43.3   \n",
              "19          1           115            70         30       96  34.6   \n",
              "20          3           126            88         41      235  39.3   \n",
              "21          8            99            84          0        0  35.4   \n",
              "22          7           196            90          0        0  39.8   \n",
              "23          9           119            80         35        0  29.0   \n",
              "24         11           143            94         33      146  36.6   \n",
              "25         10           125            70         26      115  31.1   \n",
              "26          7           147            76          0        0  39.4   \n",
              "27          1            97            66         15      140  23.2   \n",
              "28         13           145            82         19      110  22.2   \n",
              "29          5           117            92          0        0  34.1   \n",
              "30          5           109            75         26        0  36.0   \n",
              "32          3            88            58         11       54  24.8   \n",
              "..        ...           ...           ...        ...      ...   ...   \n",
              "737         8            65            72         23        0  32.0   \n",
              "738         2            99            60         17      160  36.6   \n",
              "739         1           102            74          0        0  39.5   \n",
              "740        11           120            80         37      150  42.3   \n",
              "741         3           102            44         20       94  30.8   \n",
              "742         1           109            58         18      116  28.5   \n",
              "743         9           140            94          0        0  32.7   \n",
              "744        13           153            88         37      140  40.6   \n",
              "745        12           100            84         33      105  30.0   \n",
              "746         1           147            94         41        0  49.3   \n",
              "747         1            81            74         41       57  46.3   \n",
              "748         3           187            70         22      200  36.4   \n",
              "749         6           162            62          0        0  24.3   \n",
              "750         4           136            70          0        0  31.2   \n",
              "751         1           121            78         39       74  39.0   \n",
              "752         3           108            62         24        0  26.0   \n",
              "754         8           154            78         32        0  32.4   \n",
              "755         1           128            88         39      110  36.5   \n",
              "756         7           137            90         41        0  32.0   \n",
              "757         0           123            72          0        0  36.3   \n",
              "758         1           106            76          0        0  37.5   \n",
              "759         6           190            92          0        0  35.5   \n",
              "760         2            88            58         26       16  28.4   \n",
              "761         9           170            74         31        0  44.0   \n",
              "762         9            89            62          0        0  22.5   \n",
              "763        10           101            76         48      180  32.9   \n",
              "764         2           122            70         27        0  36.8   \n",
              "765         5           121            72         23      112  26.2   \n",
              "766         1           126            60          0        0  30.1   \n",
              "767         1            93            70         31        0  30.4   \n",
              "\n",
              "     diab_pred  age  diabetes  cluster_group  \n",
              "0        0.627   50         1            0.0  \n",
              "1        0.351   31         0            0.0  \n",
              "2        0.672   32         1            0.0  \n",
              "3        0.167   21         0            0.0  \n",
              "4        2.288   33         1            0.0  \n",
              "5        0.201   30         0            0.0  \n",
              "6        0.248   26         1            0.0  \n",
              "7        0.134   29         0            0.0  \n",
              "9        0.232   54         1            0.0  \n",
              "10       0.191   30         0            0.0  \n",
              "11       0.537   34         1            0.0  \n",
              "12       1.441   57         0            0.0  \n",
              "14       0.587   51         1            0.0  \n",
              "15       0.484   32         1            0.0  \n",
              "16       0.551   31         1            0.0  \n",
              "17       0.254   31         1            0.0  \n",
              "18       0.183   33         0            0.0  \n",
              "19       0.529   32         1            0.0  \n",
              "20       0.704   27         0            0.0  \n",
              "21       0.388   50         0            0.0  \n",
              "22       0.451   41         1            0.0  \n",
              "23       0.263   29         1            0.0  \n",
              "24       0.254   51         1            0.0  \n",
              "25       0.205   41         1            0.0  \n",
              "26       0.257   43         1            0.0  \n",
              "27       0.487   22         0            0.0  \n",
              "28       0.245   57         0            0.0  \n",
              "29       0.337   38         0            0.0  \n",
              "30       0.546   60         0            0.0  \n",
              "32       0.267   22         0            0.0  \n",
              "..         ...  ...       ...            ...  \n",
              "737      0.600   42         0            0.0  \n",
              "738      0.453   21         0            0.0  \n",
              "739      0.293   42         1            0.0  \n",
              "740      0.785   48         1            0.0  \n",
              "741      0.400   26         0            0.0  \n",
              "742      0.219   22         0            0.0  \n",
              "743      0.734   45         1            0.0  \n",
              "744      1.174   39         0            0.0  \n",
              "745      0.488   46         0            0.0  \n",
              "746      0.358   27         1            0.0  \n",
              "747      1.096   32         0            0.0  \n",
              "748      0.408   36         1            0.0  \n",
              "749      0.178   50         1            0.0  \n",
              "750      1.182   22         1            0.0  \n",
              "751      0.261   28         0            0.0  \n",
              "752      0.223   25         0            0.0  \n",
              "754      0.443   45         1            0.0  \n",
              "755      1.057   37         1            0.0  \n",
              "756      0.391   39         0            0.0  \n",
              "757      0.258   52         1            0.0  \n",
              "758      0.197   26         0            0.0  \n",
              "759      0.278   66         1            0.0  \n",
              "760      0.766   22         0            0.0  \n",
              "761      0.403   43         1            0.0  \n",
              "762      0.142   33         0            0.0  \n",
              "763      0.171   63         0            0.0  \n",
              "764      0.340   27         0            0.0  \n",
              "765      0.245   30         0            0.0  \n",
              "766      0.349   47         1            0.0  \n",
              "767      0.315   23         0            0.0  \n",
              "\n",
              "[709 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    }
  ]
}